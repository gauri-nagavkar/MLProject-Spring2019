{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning\n",
    "# Emotion analysis from EEG data\n",
    "\n",
    "#### Barr Morgenstein Gauri Nagavkar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model, preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of 32 .dat files, corresponding to 32 participants.\n",
    "\n",
    "Every .dat file has EEG data and Emotion labels data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_list = ['s01.dat', 's02.dat', 's03.dat', 's04.dat', 's05.dat', 's06.dat', 's07.dat', 's08.dat', 's09.dat', 's10.dat',\n",
    "            's11.dat', 's12.dat', 's13.dat', 's14.dat', 's15.dat', 's16.dat', 's17.dat', 's18.dat', 's19.dat', 's20.dat',\n",
    "            's21.dat', 's22.dat', 's23.dat', 's24.dat', 's25.dat', 's26.dat', 's27.dat', 's28.dat', 's29.dat', 's30.dat',\n",
    "            's31.dat', 's32.dat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to extract data from .dat files in the form of X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dat_to_dict(dat_file):\n",
    "    infile= open(dat_file, 'rb')\n",
    "    data_temp= pickle.load(infile, encoding='latin1')\n",
    "    infile.close()\n",
    "    \n",
    "    X_temp= data_temp[\"data\"]\n",
    "    X_temp= X_temp[:, :-8]\n",
    "    y_temp= data_temp[\"labels\"]  \n",
    "    \n",
    "    return X_temp, y_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create arrays X (EEG data) and y (emotion labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y= dat_to_dict(dat_list[0])\n",
    "\n",
    "for i in range(1,32):\n",
    "    X1, y1= dat_to_dict(dat_list[i])\n",
    "    \n",
    "    X= np.vstack((X, X1))\n",
    "    y= np.vstack((y, y1))\n",
    "    \n",
    "    #print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale X and y\n",
    "\n",
    "Remove mean and divide by standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mean= np.mean(y, axis=0)\n",
    "y_n= (y-y_mean)/np.std(y)\n",
    "\n",
    "y_n= np.float32(y_n)\n",
    "\n",
    "\n",
    "X_mean= np.mean(X, axis=0)\n",
    "X_n= (X-X_mean)/np.std(X)\n",
    "\n",
    "X_n= np.float32(X_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape normalized X and convert it to a 2-D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamp, nchan, nt = X_n.shape\n",
    "p= nchan*nt\n",
    "X_n = X_n.reshape((nsamp, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate y into its different label components\n",
    "\n",
    "Convert the y components into binary classes by hard threshold (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Valence y\n",
    "y0 = y_n[:,0] \n",
    "y0=np.where(y0>0,1,0)\n",
    "\n",
    "#Arousal y\n",
    "y1 = y_n[:,1] \n",
    "y1=np.where(y1>0,1,0)\n",
    "\n",
    "#Dominance y\n",
    "y2 = y_n[:,2] \n",
    "y2=np.where(y2>0,1,0)\n",
    "\n",
    "#Liking y\n",
    "y3 = y_n[:,3] \n",
    "y3=np.where(y3>0,1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split normalized X and y into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0tr, X0ts, y0tr, y0ts = train_test_split(X_n, y0, test_size=0.33)\n",
    "X1tr, X1ts, y1tr, y1ts = train_test_split(X_n, y1, test_size=0.33)\n",
    "X2tr, X2ts, y2tr, y2ts = train_test_split(X_n, y2, test_size=0.33)\n",
    "X3tr, X3ts, y3tr, y3ts = train_test_split(X_n, y3, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA function for obtaining principle components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pc(X, ncomp):\n",
    "    pca= PCA(n_components= ncomp, svd_solver= 'randomized', whiten= True)\n",
    "    pca.fit(X)\n",
    "    Z= pca.transform(X)\n",
    "    \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA function to select optimal number of components for a given X and y pair for a specific model using one standard deviation rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef pc_optimal(model, range_start, range_stop, nsteps):\\n    ncomp_test= np.linspace(range_start, range_stop, nsteps, endpoint=True, dtype=int)\\n    num_nc = len(ncomp_test)\\n    \\n    acc = np.zeros((num_nc))\\n\\n# Loop over number of components to test\\n    for icomp, ncomp in enumerate(ncomp_test):\\n\\n#Fit the PCA on the scaled training data\\n        Z = pc(Xtr, ncomp)\\n        \\n        clf= model\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def pc_optimal(model, range_start, range_stop, nsteps):\n",
    "    ncomp_test= np.linspace(range_start, range_stop, nsteps, endpoint=True, dtype=int)\n",
    "    num_nc = len(ncomp_test)\n",
    "    \n",
    "    acc = np.zeros((num_nc))\n",
    "\n",
    "# Loop over number of components to test\n",
    "    for icomp, ncomp in enumerate(ncomp_test):\n",
    "\n",
    "#Fit the PCA on the scaled training data\n",
    "        Z = pc(Xtr, ncomp)\n",
    "        \n",
    "        clf= model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for Support Vector Machine (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svcc(Xtr, ytr, Xts, yts):\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(Xtr, ytr)\n",
    "\n",
    "    yhat= clf.predict(Xts)\n",
    "\n",
    "    acc = np.mean(yhat == yts)\n",
    "    \n",
    "    return yhat, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr(Xtr, ytr, Xts, yts):\n",
    "    clf = linear_model.LogisticRegression()\n",
    "    clf.fit(Xtr, ytr)\n",
    "\n",
    "    yhat= clf.predict(Xts)\n",
    "\n",
    "    acc = np.mean(yhat == yts)\n",
    "    \n",
    "    return yhat, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Function for Gaussian Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gnb(Xtr, ytr, Xts, yts):\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(Xtr,ytr)\n",
    "    \n",
    "    yhat= clf.predict(Xts)\n",
    "    \n",
    "    acc = np.mean(yhat == yts)\n",
    "    \n",
    "    return yhat, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncomp_test= np.linspace(300,400,10, endpoint=True, dtype=int)\n",
    "num_nc = len(ncomp_test)\n",
    "\n",
    "acc = np.zeros((num_nc))\n",
    "\n",
    "# Loop over number of components to test\n",
    "for icomp, ncomp in enumerate(ncomp_test):\n",
    "\n",
    " # TODO: Fit the PCA on the scaled training data\n",
    "    Z0tr= pc(X0tr, ncomp)\n",
    "\n",
    "    Z0ts= pc(X0ts, ncomp)\n",
    "\n",
    "    y0hat, acc[icomp]= svcc(Z0tr, y0tr, Z0ts, y0ts)\n",
    "    \n",
    "    #print(icomp, ncomp, acc[icomp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum accuracy for Valence using SVM is 57.45 %, obtained using 300 principle components\n"
     ]
    }
   ],
   "source": [
    "imax = np.argmax(acc)\n",
    "print(f'The maximum accuracy for Valence using SVM is {np.around(acc[imax]*100,2)} %, obtained using {ncomp_test[imax]} principle components')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncomp_test= np.linspace(250, 300, 10, endpoint=True, dtype=int)\n",
    "num_nc = len(ncomp_test)\n",
    "\n",
    "acc = np.zeros((num_nc))\n",
    "\n",
    "# Loop over number of components to test\n",
    "for icomp, ncomp in enumerate(ncomp_test):\n",
    "\n",
    " # TODO: Fit the PCA on the scaled training data\n",
    "    Z0tr= pc(X0tr, ncomp)\n",
    "\n",
    "    Z0ts= pc(X0ts, ncomp)\n",
    "\n",
    "    y0hat, acc[icomp]= lr(Z0tr, y0tr, Z0ts, y0ts)\n",
    "    \n",
    "    #print(icomp, ncomp, acc[icomp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum accuracy for Valence using Logistic regression is 55.32 %, obtained using 283 principle components\n"
     ]
    }
   ],
   "source": [
    "imax = np.argmax(acc)\n",
    "print(f'The maximum accuracy for Valence using Logistic regression is {np.around(acc[imax]*100,2)} %, obtained using {ncomp_test[imax]} principle components')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncomp_test= np.linspace(350,400, 10, endpoint=True, dtype=int)\n",
    "num_nc = len(ncomp_test)\n",
    "\n",
    "acc = np.zeros((num_nc))\n",
    "\n",
    "# Loop over number of components to test\n",
    "for icomp, ncomp in enumerate(ncomp_test):\n",
    "\n",
    " # TODO: Fit the PCA on the scaled training data\n",
    "    Z0tr= pc(X0tr, ncomp)\n",
    "\n",
    "    Z0ts= pc(X0ts, ncomp)\n",
    "\n",
    "    y0hat, acc[icomp]= gnb(Z0tr, y0tr, Z0ts, y0ts)\n",
    "    \n",
    "    #print(icomp, ncomp, acc[icomp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum accuracy for Valence using Gaussian model is 48.23 %, obtained using 383 principle components\n"
     ]
    }
   ],
   "source": [
    "imax = np.argmax(acc)\n",
    "print(f'The maximum accuracy for Valence using Gaussian model is {np.around(acc[imax]*100,2)} %, obtained using {ncomp_test[imax]} principle components')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arousal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncomp_test= np.linspace(300,350,10, endpoint=True, dtype=int)\n",
    "num_nc = len(ncomp_test)\n",
    "\n",
    "acc = np.zeros((num_nc))\n",
    "\n",
    "# Loop over number of components to test\n",
    "for icomp, ncomp in enumerate(ncomp_test):\n",
    "\n",
    " # TODO: Fit the PCA on the scaled training data\n",
    "    Z1tr= pc(X1tr, ncomp)\n",
    "\n",
    "    Z1ts= pc(X1ts, ncomp)\n",
    "\n",
    "    y1hat, acc[icomp]= svcc(Z1tr, y1tr, Z1ts, y1ts)\n",
    "    \n",
    "    #print(icomp, ncomp, acc[icomp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum accuracy for Arousal using SVM is 56.26 %, obtained using 322 principle components\n"
     ]
    }
   ],
   "source": [
    "imax = np.argmax(acc)\n",
    "print(f'The maximum accuracy for Arousal using SVM is {np.around(acc[imax]*100,2)} %, obtained using {ncomp_test[imax]} principle components')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncomp_test= np.linspace(65,120,10, endpoint=True, dtype=int)\n",
    "num_nc = len(ncomp_test)\n",
    "\n",
    "acc = np.zeros((num_nc))\n",
    "\n",
    "# Loop over number of components to test\n",
    "for icomp, ncomp in enumerate(ncomp_test):\n",
    "\n",
    " # TODO: Fit the PCA on the scaled training data\n",
    "    Z1tr= pc(X1tr, ncomp)\n",
    "\n",
    "    Z1ts= pc(X1ts, ncomp)\n",
    "\n",
    "    y1hat, acc[icomp]= lr(Z1tr, y1tr, Z1ts, y1ts)\n",
    "    \n",
    "    #print(icomp, ncomp, acc[icomp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum accuracy for Arousal using Logistic regression is 56.74 %, obtained using 95 principle components\n"
     ]
    }
   ],
   "source": [
    "imax = np.argmax(acc)\n",
    "print(f'The maximum accuracy for Arousal using Logistic regression is {np.around(acc[imax]*100,2)} %, obtained using {ncomp_test[imax]} principle components')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncomp_test= np.linspace(250, 330, 10, endpoint=True, dtype=int)\n",
    "num_nc = len(ncomp_test)\n",
    "\n",
    "acc = np.zeros((num_nc))\n",
    "\n",
    "# Loop over number of components to test\n",
    "for icomp, ncomp in enumerate(ncomp_test):\n",
    "\n",
    " # TODO: Fit the PCA on the scaled training data\n",
    "    Z1tr= pc(X1tr, ncomp)\n",
    "\n",
    "    Z1ts= pc(X1ts, ncomp)\n",
    "\n",
    "    y1hat, acc[icomp]= gnb(Z1tr, y1tr, Z1ts, y1ts)\n",
    "    \n",
    "    #print(icomp, ncomp, acc[icomp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum accuracy for Arousal using Gaussian model is 53.19 %, obtained using 312 principle components\n"
     ]
    }
   ],
   "source": [
    "imax = np.argmax(acc)\n",
    "print(f'The maximum accuracy for Arousal using Gaussian model is {np.around(acc[imax]*100,2)} %, obtained using {ncomp_test[imax]} principle components')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dominance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncomp_test= np.linspace(60,120,10, endpoint=True, dtype=int)\n",
    "num_nc = len(ncomp_test)\n",
    "\n",
    "acc = np.zeros((num_nc))\n",
    "\n",
    "# Loop over number of components to test\n",
    "for icomp, ncomp in enumerate(ncomp_test):\n",
    "\n",
    " # TODO: Fit the PCA on the scaled training data\n",
    "    Z2tr= pc(X2tr, ncomp)\n",
    "\n",
    "    Z2ts= pc(X2ts, ncomp)\n",
    "\n",
    "    y2hat, acc[icomp]= svcc(Z2tr, y2tr, Z2ts, y2ts)\n",
    "    \n",
    "    #print(icomp, ncomp, acc[icomp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum accuracy for Dominance using SVM is 52.25 %, obtained using 86 principle components\n"
     ]
    }
   ],
   "source": [
    "imax = np.argmax(acc)\n",
    "print(f'The maximum accuracy for Dominance using SVM is {np.around(acc[imax]*100,2)} %, obtained using {ncomp_test[imax]} principle components')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncomp_test= np.linspace(200,260,10, endpoint=True, dtype=int)\n",
    "num_nc = len(ncomp_test)\n",
    "\n",
    "acc = np.zeros((num_nc))\n",
    "\n",
    "# Loop over number of components to test\n",
    "for icomp, ncomp in enumerate(ncomp_test):\n",
    "\n",
    " # TODO: Fit the PCA on the scaled training data\n",
    "    Z2tr= pc(X2tr, ncomp)\n",
    "\n",
    "    Z2ts= pc(X2ts, ncomp)\n",
    "\n",
    "    y2hat, acc[icomp]= lr(Z2tr, y2tr, Z2ts, y2ts)\n",
    "    \n",
    "    #print(icomp, ncomp, acc[icomp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum accuracy for Dominance using Logistic regression is 57.45 %, obtained using 220 principle components\n"
     ]
    }
   ],
   "source": [
    "imax = np.argmax(acc)\n",
    "print(f'The maximum accuracy for Dominance using Logistic regression is {np.around(acc[imax]*100,2)} %, obtained using {ncomp_test[imax]} principle components')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncomp_test= np.linspace(350,400, 10, endpoint=True, dtype=int)\n",
    "num_nc = len(ncomp_test)\n",
    "\n",
    "acc = np.zeros((num_nc))\n",
    "\n",
    "# Loop over number of components to test\n",
    "for icomp, ncomp in enumerate(ncomp_test):\n",
    "\n",
    " # TODO: Fit the PCA on the scaled training data\n",
    "    Z2tr= pc(X2tr, ncomp)\n",
    "\n",
    "    Z2ts= pc(X2ts, ncomp)\n",
    "\n",
    "    y2hat, acc[icomp]= gnb(Z2tr, y2tr, Z2ts, y2ts)\n",
    "    \n",
    "    #print(icomp, ncomp, acc[icomp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imax = np.argmax(acc)\n",
    "print(f'The maximum accuracy for Dominance using Gaussian model is {np.around(acc[imax]*100,2)} %, obtained using {ncomp_test[imax]} principle components')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
