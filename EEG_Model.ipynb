{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning\n",
    "# Emotion analysis from EEG data\n",
    "\n",
    "#### Barr Morgenstein Gauri Nagavkar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model, preprocessing\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of 32 .dat files, corresponding to 32 participants.\n",
    "\n",
    "Every .dat file has EEG data and Emotion labels data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_list = ['s01.dat', 's02.dat', 's03.dat', 's04.dat', 's05.dat', 's06.dat', 's07.dat', 's08.dat', 's09.dat', 's10.dat',\n",
    "            's11.dat', 's12.dat', 's13.dat', 's14.dat', 's15.dat', 's16.dat', 's17.dat', 's18.dat', 's19.dat', 's20.dat',\n",
    "            's21.dat', 's22.dat', 's23.dat', 's24.dat', 's25.dat', 's26.dat', 's27.dat', 's28.dat', 's29.dat', 's30.dat',\n",
    "            's31.dat', 's32.dat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to extract data from .dat files in the form of X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dat_to_dict(dat_file):\n",
    "    infile= open(dat_file, 'rb')\n",
    "    data_temp= pickle.load(infile, encoding='latin1')\n",
    "    infile.close()\n",
    "    \n",
    "    X_temp= data_temp[\"data\"]\n",
    "    X_temp= X_temp[:, :-8]\n",
    "    y_temp= data_temp[\"labels\"]  \n",
    "    \n",
    "    return X_temp, y_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create arrays X (EEG data) and y (emotion labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y= dat_to_dict(dat_list[0])\n",
    "\n",
    "for i in range(1,32):\n",
    "    X1, y1= dat_to_dict(dat_list[i])\n",
    "    \n",
    "    X= np.vstack((X, X1))\n",
    "    y= np.vstack((y, y1))\n",
    "    \n",
    "    #print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale X and y\n",
    "\n",
    "Remove mean and divide by standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mean= np.mean(y, axis=0)\n",
    "y_n= (y-y_mean)/np.std(y)\n",
    "\n",
    "y_n= np.float32(y_n)\n",
    "\n",
    "\n",
    "X_mean= np.mean(X, axis=0)\n",
    "X_n= (X-X_mean)/np.std(X)\n",
    "\n",
    "X_n= np.float32(X_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape normalized X and convert it to a 2-D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamp, nchan, nt = X_n.shape\n",
    "p= nchan*nt\n",
    "X_n = X_n.reshape((nsamp, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate y into its different label components\n",
    "\n",
    "Convert the y components into binary classes by hard threshold (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Valence y\n",
    "y0 = y_n[:,0] \n",
    "y0=np.where(y0>0,1,0)\n",
    "\n",
    "#Arousal y\n",
    "y1 = y_n[:,1] \n",
    "y1=np.where(y1>0,1,0)\n",
    "\n",
    "#Dominance y\n",
    "y2 = y_n[:,2] \n",
    "y2=np.where(y2>0,1,0)\n",
    "\n",
    "#Liking y\n",
    "y3 = y_n[:,3] \n",
    "y3=np.where(y3>0,1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split normalized X and y into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0tr, X0ts, y0tr, y0ts = train_test_split(X_n, y0, test_size=0.33)\n",
    "X1tr, X1ts, y1tr, y1ts = train_test_split(X_n, y1, test_size=0.33)\n",
    "X2tr, X2ts, y2tr, y2ts = train_test_split(X_n, y2, test_size=0.33)\n",
    "X3tr, X3ts, y3tr, y3ts = train_test_split(X_n, y3, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA function for obtaining principle components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pc(X, ncomp):\n",
    "    pca= PCA(n_components= ncomp, svd_solver= 'randomized', whiten= True)\n",
    "    pca.fit(X)\n",
    "    Z= pca.transform(X)\n",
    "    \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA function to select optimal number of components for a given X and y pair for a specific model using one standard deviation rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef pc_optimal(model, range_start, range_stop, nsteps):\\n    ncomp_test= np.linspace(range_start, range_stop, nsteps, endpoint=True, dtype=int)\\n    num_nc = len(ncomp_test)\\n    \\n    acc = np.zeros((num_nc))\\n\\n# Loop over number of components to test\\n    for icomp, ncomp in enumerate(ncomp_test):\\n\\n#Fit the PCA on the scaled training data\\n        Z = pc(Xtr, ncomp)\\n        \\n        clf= model\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def pc_optimal(model, range_start, range_stop, nsteps):\n",
    "    ncomp_test= np.linspace(range_start, range_stop, nsteps, endpoint=True, dtype=int)\n",
    "    num_nc = len(ncomp_test)\n",
    "    \n",
    "    acc = np.zeros((num_nc))\n",
    "\n",
    "# Loop over number of components to test\n",
    "    for icomp, ncomp in enumerate(ncomp_test):\n",
    "\n",
    "#Fit the PCA on the scaled training data\n",
    "        Z = pc(Xtr, ncomp)\n",
    "        \n",
    "        clf= model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for Support Vector Machine (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svcc(Xtr, ytr, Xts, yts):\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(Xtr, ytr)\n",
    "\n",
    "    yhat= clf.predict(Xts)\n",
    "\n",
    "    acc = np.mean(yhat == yts)\n",
    "    \n",
    "    return yhat, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr(Xtr, ytr, Xts, yts):\n",
    "    clf = linear_model.LogisticRegression()\n",
    "    clf.fit(Xtr, ytr)\n",
    "\n",
    "    yhat= clf.predict(Xts)\n",
    "\n",
    "    acc = np.mean(yhat == yts)\n",
    "    \n",
    "    return yhat, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Function for Gaussian Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gnb(Xtr, ytr, Xts, yts):\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(Xtr,ytr)\n",
    "    \n",
    "    yhat= clf.predict(Xts)\n",
    "    \n",
    "    return yhat, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncomp_test= np.linspace(300,400,10, endpoint=True, dtype=int)\n",
    "num_nc = len(ncomp_test)\n",
    "\n",
    "# Accuracy: acc[icomp,ifold] is test accuracy when using `ncomp = ncomp_test[icomp]` in fold `ifold`.\n",
    "acc = np.zeros((num_nc))\n",
    "\n",
    "# Loop over number of components to test\n",
    "for icomp, ncomp in enumerate(ncomp_test):\n",
    "\n",
    " # TODO: Fit the PCA on the scaled training data\n",
    "    Z0tr= pc(X0tr, ncomp)\n",
    "\n",
    "    Z0ts= pc(X0ts, ncomp)\n",
    "\n",
    "    y0hat, acc[icomp]= svcc(Z0tr, y0tr, Z0ts, y0ts)\n",
    "    \n",
    "    print(icomp, ncomp, acc[icomp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KedarPotdar\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-58e564559f16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mZ0ts\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX0ts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mncomp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0my0hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0micomp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ0tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my0tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ0ts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my0ts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0micomp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mncomp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0micomp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "ncomp_test= np.linspace(250, 300, 10, endpoint=True, dtype=int)\n",
    "num_nc = len(ncomp_test)\n",
    "\n",
    "# Accuracy: acc[icomp,ifold] is test accuracy when using `ncomp = ncomp_test[icomp]` in fold `ifold`.\n",
    "acc = np.zeros((num_nc))\n",
    "\n",
    "# Loop over number of components to test\n",
    "for icomp, ncomp in enumerate(ncomp_test):\n",
    "\n",
    " # TODO: Fit the PCA on the scaled training data\n",
    "    Z0tr= pc(X0tr, ncomp)\n",
    "\n",
    "    Z0ts= pc(X0ts, ncomp)\n",
    "\n",
    "    y0hat, acc[icomp]= lr(Z0tr, y0tr, Z0ts, y0ts)\n",
    "    \n",
    "    print(icomp, ncomp, acc[icomp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncomp_test= np.linspace(10,400, 20, endpoint=True, dtype=int)\n",
    "num_nc = len(ncomp_test)\n",
    "\n",
    "# Accuracy: acc[icomp,ifold] is test accuracy when using `ncomp = ncomp_test[icomp]` in fold `ifold`.\n",
    "acc = np.zeros((num_nc))\n",
    "\n",
    "# Loop over number of components to test\n",
    "for icomp, ncomp in enumerate(ncomp_test):\n",
    "\n",
    " # TODO: Fit the PCA on the scaled training data\n",
    "    Z0tr= pc(X0tr, ncomp)\n",
    "\n",
    "    Z0ts= pc(X0ts, ncomp)\n",
    "\n",
    "    y0hat, acc= gnb(Z0tr, y0tr, Z0ts, y0ts)\n",
    "    \n",
    "    print(icomp, ncomp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
